{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch lerobot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lerobot.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers num2words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add parent directory to path to import train module\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "from train_smolvla import train\n",
        "\n",
        "print(\"\\nStarting training process...\")\n",
        "print(\"Note: We'll use a public dataset for training as our sample is too small\")\n",
        "\n",
        "# Create a temporary directory for training output\n",
        "train_output_dir = Path('model_output')\n",
        "\n",
        "print(f\"Training output will be saved to: {train_output_dir}\")\n",
        "\n",
        "train(output_dir=str(train_output_dir), dataset_id=\"ISdept/piper_arm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 164 episode folders\n",
            "Processing episode 1 in folder data/piper_training_data/episode1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 150/150 [00:00<00:00, 11203.93 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1177.84ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 2 in folder data/piper_training_data/episode2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 35598.71 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1300.16ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 3 in folder data/piper_training_data/episode3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 137/137 [00:00<00:00, 43867.44 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1232.89ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 4 in folder data/piper_training_data/episode4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 108/108 [00:00<00:00, 35281.94 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1254.65ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 5 in folder data/piper_training_data/episode5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 112/112 [00:00<00:00, 37835.22 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1623.81ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 6 in folder data/piper_training_data/episode6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 112/112 [00:00<00:00, 39830.60 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1264.11ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 7 in folder data/piper_training_data/episode7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 129/129 [00:00<00:00, 40912.30 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1234.71ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 8 in folder data/piper_training_data/episode8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 124/124 [00:00<00:00, 41501.25 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1020.51ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 9 in folder data/piper_training_data/episode9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 208/208 [00:00<00:00, 87794.63 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1294.94ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 10 in folder data/piper_training_data/episode10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 106/106 [00:00<00:00, 35593.33 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1276.03ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 11 in folder data/piper_training_data/episode11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 88/88 [00:00<00:00, 26588.30 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1636.48ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 12 in folder data/piper_training_data/episode12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 29027.38 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1490.51ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 13 in folder data/piper_training_data/episode13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 93/93 [00:00<00:00, 32136.29 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1228.56ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 14 in folder data/piper_training_data/episode14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 30294.14 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1153.23ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 15 in folder data/piper_training_data/episode15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 29129.49 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 962.44ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 16 in folder data/piper_training_data/episode16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 32478.44 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1201.81ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 17 in folder data/piper_training_data/episode17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 99/99 [00:00<00:00, 39273.25 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1483.13ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 18 in folder data/piper_training_data/episode18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 108/108 [00:00<00:00, 39819.34 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 871.82ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 19 in folder data/piper_training_data/episode19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 103/103 [00:00<00:00, 30318.85 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1506.03ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 20 in folder data/piper_training_data/episode20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 89/89 [00:00<00:00, 31831.93 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1381.07ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 21 in folder data/piper_training_data/episode21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 106/106 [00:00<00:00, 31075.43 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1129.93ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 22 in folder data/piper_training_data/episode22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 105/105 [00:00<00:00, 32487.60 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1140.38ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 23 in folder data/piper_training_data/episode23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 117/117 [00:00<00:00, 39224.17 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1128.41ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 24 in folder data/piper_training_data/episode24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 105/105 [00:00<00:00, 32052.54 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1430.53ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 25 in folder data/piper_training_data/episode25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 135/135 [00:00<00:00, 41668.34 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1008.00ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 26 in folder data/piper_training_data/episode26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 37462.39 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1111.07ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 27 in folder data/piper_training_data/episode27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 121/121 [00:00<00:00, 40701.80 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1268.69ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 28 in folder data/piper_training_data/episode28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 110/110 [00:00<00:00, 34002.02 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1161.21ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 29 in folder data/piper_training_data/episode29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 34456.84 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1206.30ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 30 in folder data/piper_training_data/episode30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 29047.71 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1406.07ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 31 in folder data/piper_training_data/episode31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 38692.84 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1366.22ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 32 in folder data/piper_training_data/episode32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 122/122 [00:00<00:00, 38610.51 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1044.92ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 33 in folder data/piper_training_data/episode33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 107/107 [00:00<00:00, 40135.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1035.37ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 34 in folder data/piper_training_data/episode34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 92/92 [00:00<00:00, 30302.81 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1494.76ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 35 in folder data/piper_training_data/episode35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 28415.46 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1257.66ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 36 in folder data/piper_training_data/episode36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 96/96 [00:00<00:00, 31573.21 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1524.09ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 37 in folder data/piper_training_data/episode37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 87/87 [00:00<00:00, 28208.45 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1546.00ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 38 in folder data/piper_training_data/episode38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 80/80 [00:00<00:00, 28460.08 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1644.83ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 39 in folder data/piper_training_data/episode39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 113/113 [00:00<00:00, 41167.06 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1533.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 40 in folder data/piper_training_data/episode40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 86/86 [00:00<00:00, 29737.03 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1607.63ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 41 in folder data/piper_training_data/episode41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 98/98 [00:00<00:00, 37445.73 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1628.22ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 42 in folder data/piper_training_data/episode42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 74/74 [00:00<00:00, 26294.35 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1274.09ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 43 in folder data/piper_training_data/episode43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 97/97 [00:00<00:00, 32581.68 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1107.26ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 44 in folder data/piper_training_data/episode44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 84/84 [00:00<00:00, 29187.44 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1531.33ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 45 in folder data/piper_training_data/episode45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 90/90 [00:00<00:00, 34106.19 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1534.13ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 46 in folder data/piper_training_data/episode46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 116/116 [00:00<00:00, 36744.90 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1356.94ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 47 in folder data/piper_training_data/episode47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 38939.71 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1544.86ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 48 in folder data/piper_training_data/episode48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 108/108 [00:00<00:00, 34682.25 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1218.21ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 49 in folder data/piper_training_data/episode49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 84/84 [00:00<00:00, 27779.04 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1266.01ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 50 in folder data/piper_training_data/episode50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 107/107 [00:00<00:00, 32162.14 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1683.78ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 51 in folder data/piper_training_data/episode51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 28668.05 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1416.52ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 52 in folder data/piper_training_data/episode52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 78/78 [00:00<00:00, 27445.95 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1113.73ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 53 in folder data/piper_training_data/episode53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 121/121 [00:00<00:00, 46398.86 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1312.77ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 54 in folder data/piper_training_data/episode54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 132/132 [00:00<00:00, 40904.92 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1723.92ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 55 in folder data/piper_training_data/episode55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 97/97 [00:00<00:00, 41438.94 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1567.96ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 56 in folder data/piper_training_data/episode56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 102/102 [00:00<00:00, 39289.10 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1510.37ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 57 in folder data/piper_training_data/episode57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 33519.92 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 875.64ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 58 in folder data/piper_training_data/episode58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 125/125 [00:00<00:00, 41033.73 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1495.30ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 59 in folder data/piper_training_data/episode59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 67/67 [00:00<00:00, 24676.71 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1576.81ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 60 in folder data/piper_training_data/episode60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 83/83 [00:00<00:00, 28617.12 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1468.59ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 61 in folder data/piper_training_data/episode61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 132/132 [00:00<00:00, 52112.96 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1548.28ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 62 in folder data/piper_training_data/episode62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 90/90 [00:00<00:00, 36317.81 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1515.28ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 63 in folder data/piper_training_data/episode63\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 92/92 [00:00<00:00, 35453.51 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1329.41ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 64 in folder data/piper_training_data/episode64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 153/153 [00:00<00:00, 53705.62 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1545.43ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 65 in folder data/piper_training_data/episode65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 114/114 [00:00<00:00, 44724.60 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1683.78ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 66 in folder data/piper_training_data/episode66\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 83/83 [00:00<00:00, 31714.24 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1447.31ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 67 in folder data/piper_training_data/episode67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 110/110 [00:00<00:00, 42161.51 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1514.74ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 68 in folder data/piper_training_data/episode68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 84/84 [00:00<00:00, 30435.52 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1672.37ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 69 in folder data/piper_training_data/episode69\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 97/97 [00:00<00:00, 35886.70 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1521.88ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 70 in folder data/piper_training_data/episode70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 92/92 [00:00<00:00, 35330.16 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1477.91ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 71 in folder data/piper_training_data/episode71\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 86/86 [00:00<00:00, 32935.55 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1570.31ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 72 in folder data/piper_training_data/episode72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 84/84 [00:00<00:00, 30791.95 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1342.18ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 73 in folder data/piper_training_data/episode73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 78/78 [00:00<00:00, 29093.44 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1555.17ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 74 in folder data/piper_training_data/episode74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 89/89 [00:00<00:00, 33149.19 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1548.28ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 75 in folder data/piper_training_data/episode75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 98/98 [00:00<00:00, 33423.47 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1486.29ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 76 in folder data/piper_training_data/episode76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 111/111 [00:00<00:00, 44184.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1789.38ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 77 in folder data/piper_training_data/episode77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 82/82 [00:00<00:00, 27055.77 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1392.53ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 78 in folder data/piper_training_data/episode78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 32239.32 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1739.65ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 79 in folder data/piper_training_data/episode79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 87/87 [00:00<00:00, 35110.60 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1757.14ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 80 in folder data/piper_training_data/episode80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 93/93 [00:00<00:00, 34192.70 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1300.16ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 81 in folder data/piper_training_data/episode81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 91/91 [00:00<00:00, 33480.85 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1538.63ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 82 in folder data/piper_training_data/episode82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 32672.96 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1678.39ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 83 in folder data/piper_training_data/episode83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 34139.22 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1548.28ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 84 in folder data/piper_training_data/episode84\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 81/81 [00:00<00:00, 30623.64 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1631.39ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 85 in folder data/piper_training_data/episode85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 34548.25 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1592.37ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 86 in folder data/piper_training_data/episode86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 124/124 [00:00<00:00, 48839.67 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1468.59ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 87 in folder data/piper_training_data/episode87\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 120/120 [00:00<00:00, 50382.03 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1446.81ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 88 in folder data/piper_training_data/episode88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 126/126 [00:00<00:00, 49184.02 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1615.06ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 89 in folder data/piper_training_data/episode89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 103/103 [00:00<00:00, 40049.44 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1707.08ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 90 in folder data/piper_training_data/episode90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 87/87 [00:00<00:00, 33067.92 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1691.25ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 91 in folder data/piper_training_data/episode91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 114/114 [00:00<00:00, 47896.49 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1508.20ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 92 in folder data/piper_training_data/episode92\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 113/113 [00:00<00:00, 43763.28 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1557.48ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 93 in folder data/piper_training_data/episode93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 133/133 [00:00<00:00, 58486.31 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1381.52ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 94 in folder data/piper_training_data/episode94\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 121/121 [00:00<00:00, 39961.48 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1663.75ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 95 in folder data/piper_training_data/episode95\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 89/89 [00:00<00:00, 26696.21 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1096.55ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 96 in folder data/piper_training_data/episode96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 125/125 [00:00<00:00, 48861.88 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1785.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 97 in folder data/piper_training_data/episode97\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 126/126 [00:00<00:00, 52021.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1572.08ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 98 in folder data/piper_training_data/episode98\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 108/108 [00:00<00:00, 33551.95 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1312.77ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 99 in folder data/piper_training_data/episode99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 87/87 [00:00<00:00, 26252.12 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1398.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 100 in folder data/piper_training_data/episode100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 91/91 [00:00<00:00, 24998.80 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1353.00ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 101 in folder data/piper_training_data/episode101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 102/102 [00:00<00:00, 34179.04 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1529.09ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 102 in folder data/piper_training_data/episode102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 110/110 [00:00<00:00, 35575.10 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1550.00ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 103 in folder data/piper_training_data/episode103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 98/98 [00:00<00:00, 30368.81 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1487.87ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 104 in folder data/piper_training_data/episode104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 89/89 [00:00<00:00, 28495.65 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1197.69ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 105 in folder data/piper_training_data/episode105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 77/77 [00:00<00:00, 26552.78 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1780.26ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 106 in folder data/piper_training_data/episode106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 29266.17 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 951.31ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 107 in folder data/piper_training_data/episode107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 90/90 [00:00<00:00, 27312.59 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1133.60ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 108 in folder data/piper_training_data/episode108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 98/98 [00:00<00:00, 32045.04 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1418.43ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 109 in folder data/piper_training_data/episode109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 116/116 [00:00<00:00, 35539.76 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1463.98ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 110 in folder data/piper_training_data/episode110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 119/119 [00:00<00:00, 36102.87 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1533.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 111 in folder data/piper_training_data/episode111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 40292.75 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1644.83ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 112 in folder data/piper_training_data/episode112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 91/91 [00:00<00:00, 34707.80 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1412.22ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 113 in folder data/piper_training_data/episode113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 104/104 [00:00<00:00, 35121.39 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1111.37ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 114 in folder data/piper_training_data/episode114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 113/113 [00:00<00:00, 41898.55 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1531.33ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 115 in folder data/piper_training_data/episode115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 88/88 [00:00<00:00, 34482.32 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1730.32ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 116 in folder data/piper_training_data/episode116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 86/86 [00:00<00:00, 33632.65 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1667.05ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 117 in folder data/piper_training_data/episode117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 105/105 [00:00<00:00, 41614.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1510.37ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 118 in folder data/piper_training_data/episode118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 128/128 [00:00<00:00, 49922.90 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1439.36ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 119 in folder data/piper_training_data/episode119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 115/115 [00:00<00:00, 34145.90 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1013.36ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 120 in folder data/piper_training_data/episode120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 120/120 [00:00<00:00, 39444.87 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1373.38ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 121 in folder data/piper_training_data/episode121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 120/120 [00:00<00:00, 42751.76 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1432.97ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 122 in folder data/piper_training_data/episode122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 100/100 [00:00<00:00, 31326.49 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1565.04ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 123 in folder data/piper_training_data/episode123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 112/112 [00:00<00:00, 41461.79 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1591.77ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 124 in folder data/piper_training_data/episode124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 100/100 [00:00<00:00, 35968.65 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1219.27ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 125 in folder data/piper_training_data/episode125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 84/84 [00:00<00:00, 24388.86 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1089.43ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 126 in folder data/piper_training_data/episode126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 105/105 [00:00<00:00, 31075.50 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1370.24ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 127 in folder data/piper_training_data/episode127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 60/60 [00:00<00:00, 20298.29 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1334.92ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 128 in folder data/piper_training_data/episode128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 112/112 [00:00<00:00, 36554.51 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1360.46ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 129 in folder data/piper_training_data/episode129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 100/100 [00:00<00:00, 29706.81 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1499.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 130 in folder data/piper_training_data/episode130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 81/81 [00:00<00:00, 29581.07 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1546.00ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 131 in folder data/piper_training_data/episode131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 76/76 [00:00<00:00, 24374.30 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1575.03ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 132 in folder data/piper_training_data/episode132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 75/75 [00:00<00:00, 24662.70 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1200.43ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 133 in folder data/piper_training_data/episode133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 91/91 [00:00<00:00, 27317.61 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1227.12ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 134 in folder data/piper_training_data/episode134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 76/76 [00:00<00:00, 25282.92 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1499.04ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 135 in folder data/piper_training_data/episode135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 76/76 [00:00<00:00, 28648.07 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1249.79ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 136 in folder data/piper_training_data/episode136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 100/100 [00:00<00:00, 32415.98 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1470.65ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 137 in folder data/piper_training_data/episode137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 79/79 [00:00<00:00, 24610.07 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1333.22ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 138 in folder data/piper_training_data/episode138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 32442.51 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1219.27ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 139 in folder data/piper_training_data/episode139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 79/79 [00:00<00:00, 28562.19 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1449.31ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 140 in folder data/piper_training_data/episode140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 111/111 [00:00<00:00, 40277.51 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1721.80ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 141 in folder data/piper_training_data/episode141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 38857.52 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1533.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 142 in folder data/piper_training_data/episode142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 82/82 [00:00<00:00, 33718.91 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1625.70ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 143 in folder data/piper_training_data/episode143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 75/75 [00:00<00:00, 29265.31 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1639.68ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 144 in folder data/piper_training_data/episode144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 107/107 [00:00<00:00, 40636.59 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1669.71ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 145 in folder data/piper_training_data/episode145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 126/126 [00:00<00:00, 45799.66 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1404.66ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 146 in folder data/piper_training_data/episode146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 33928.04 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1550.57ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 147 in folder data/piper_training_data/episode147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 109/109 [00:00<00:00, 41824.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1642.25ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 148 in folder data/piper_training_data/episode148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 120/120 [00:00<00:00, 46620.64 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1163.79ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 149 in folder data/piper_training_data/episode149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 125/125 [00:00<00:00, 48770.98 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1404.66ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 150 in folder data/piper_training_data/episode150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 70/70 [00:00<00:00, 25008.63 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1757.14ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 151 in folder data/piper_training_data/episode151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 103/103 [00:00<00:00, 40232.20 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1394.38ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 152 in folder data/piper_training_data/episode152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 82/82 [00:00<00:00, 31669.70 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1381.07ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 153 in folder data/piper_training_data/episode153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 77/77 [00:00<00:00, 28071.40 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1384.72ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 154 in folder data/piper_training_data/episode154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 83/83 [00:00<00:00, 17555.58 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 927.74ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 155 in folder data/piper_training_data/episode155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 106/106 [00:00<00:00, 44006.36 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1396.70ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 156 in folder data/piper_training_data/episode156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 86/86 [00:00<00:00, 32040.34 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1032.06ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 157 in folder data/piper_training_data/episode157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 83/83 [00:00<00:00, 33004.10 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1903.91ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 158 in folder data/piper_training_data/episode158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 89/89 [00:00<00:00, 38161.22 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1545.43ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 159 in folder data/piper_training_data/episode159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 86/86 [00:00<00:00, 33423.85 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1818.87ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 160 in folder data/piper_training_data/episode160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 37452.70 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1620.67ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 161 in folder data/piper_training_data/episode161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 74/74 [00:00<00:00, 30453.15 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1572.08ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 162 in folder data/piper_training_data/episode162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 66/66 [00:00<00:00, 20853.04 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1227.48ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 163 in folder data/piper_training_data/episode163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 91/91 [00:00<00:00, 35311.47 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1513.10ba/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing episode 164 in folder data/piper_training_data/episode164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 73/73 [00:00<00:00, 30094.77 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1608.25ba/s]\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n",
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/datasets/compute_stats.py:154: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
            "  hist, _ = np.histogram(batch[:, i], bins=self._bin_edges[i])\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# Add the src directory to the path so we can import prepare_dataset\n",
        "from data_processing.prepare_dataset import process_session, create_tasks_parquet, create_episodes_parquet_index, update_total_frames_from_episodes, compute_and_save_dataset_stats\n",
        "from data_processing.episode_data import EpisodeData, CameraData\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "ROOT_FOLDER = Path(\"data/piper_training_data/\")  # Root folder containing episode subfolders\n",
        "OUTPUT_FOLDER = Path(\"output/\")  # Output folder for processed dataset\n",
        "REPO_ID = \"ISDept/piper_arm\"  # Your desired Hugging Face repo ID\n",
        "# ---------------------\n",
        "\n",
        "def find_episode_folders(root_folder):\n",
        "    \"\"\"Find all episode folders with naming convention episode1, episode2, etc.\"\"\"\n",
        "    episode_folders = []\n",
        "    pattern = re.compile(r'^episode(\\d+)$', re.IGNORECASE)\n",
        "    \n",
        "    for item in root_folder.iterdir():\n",
        "        if item.is_dir():\n",
        "            match = pattern.match(item.name)\n",
        "            if match:\n",
        "                episode_folders.append((item, int(match.group(1))))\n",
        "    \n",
        "    # Sort by episode number\n",
        "    episode_folders.sort(key=lambda x: x[1])\n",
        "    return episode_folders\n",
        "\n",
        "def find_json_and_videos(episode_folder):\n",
        "    \"\"\"Find JSON file and video files in the episode folder.\"\"\"\n",
        "    json_files = list(episode_folder.glob(\"*.json\"))\n",
        "    if not json_files:\n",
        "        raise FileNotFoundError(f\"No JSON file found in {episode_folder}\")\n",
        "    if len(json_files) > 1:\n",
        "        print(f\"Warning: Multiple JSON files found in {episode_folder}, using {json_files[0]}\")\n",
        "    \n",
        "    json_path = json_files[0]\n",
        "    \n",
        "    # Find video files (assuming common video extensions)\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
        "    video_files = []\n",
        "    for ext in video_extensions:\n",
        "        video_files.extend(episode_folder.glob(f\"*{ext}\"))\n",
        "    \n",
        "    return json_path, video_files\n",
        "\n",
        "def get_camera_name_from_video_path(video_path):\n",
        "    \"\"\"Determine camera name based on video filename content.\"\"\"\n",
        "    filename = video_path.stem.lower()\n",
        "    if 'front' in filename:\n",
        "        return 'front'\n",
        "    elif 'right' in filename:\n",
        "        return 'right'\n",
        "    elif 'gripper' in filename:\n",
        "        return 'gripper'\n",
        "    else:\n",
        "        # Fallback: use the last part of filename after underscore\n",
        "        return video_path.stem.split('_')[-1]\n",
        "      \n",
        "def process_episode_folder(episode_folder, episode_idx, global_index_offset, last_frames_to_chop):\n",
        "    \"\"\"Process a single episode folder.\"\"\"\n",
        "    json_path, video_files = find_json_and_videos(episode_folder)\n",
        "    \n",
        "    # Create CameraData objects from video files\n",
        "    cameras_list = []\n",
        "    for video_path in video_files:\n",
        "        # Extract camera name from filename (you might want to customize this logic)\n",
        "        camera_name = get_camera_name_from_video_path(video_path)\n",
        "        cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "    \n",
        "    episode_data = EpisodeData(\n",
        "        joint_data_json_path=str(json_path), \n",
        "        episode_index=episode_idx, \n",
        "        fps=10, \n",
        "        global_index_offset=global_index_offset, \n",
        "        cameras=cameras_list,\n",
        "        folder = episode_folder,\n",
        "        task_description = \"Pick up the cube and place it into the container.\"\n",
        "    )\n",
        "    \n",
        "    # Process the first episode differently to create initial files\n",
        "    is_first_episode = (episode_idx == 1)\n",
        "    num_of_frames = process_session(episode_data, OUTPUT_FOLDER, is_first_episode, last_frames_to_chop)\n",
        "    episode_data.num_of_frames = num_of_frames\n",
        "    return episode_data\n",
        "\n",
        "def main():\n",
        "    # Find all episode folders\n",
        "    episode_folders = find_episode_folders(ROOT_FOLDER)\n",
        "    \n",
        "    if not episode_folders:\n",
        "        print(f\"No episode folders found in {ROOT_FOLDER}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Found {len(episode_folders)} episode folders\")\n",
        "    \n",
        "    last_frames_to_chop = 30\n",
        "    global_index_offset = 0\n",
        "    all_episodes_data = []\n",
        "    \n",
        "    \n",
        "    # Process each episode folder\n",
        "    for episode_folder, episode_idx in episode_folders:\n",
        "        print(f\"Processing episode {episode_idx} in folder {episode_folder}\")\n",
        "        \n",
        "        if episode_idx == 3:\n",
        "            last_frames_to_chop = 42\n",
        "        elif episode_idx == 7 or episode_idx == 32 or episode_idx == 46 or episode_idx == 76 or episode_idx == 87 or episode_idx == 88 \\\n",
        "          or episode_idx ==  89 or episode_idx == 102 or episode_idx == 103 or episode_idx == 108 or episode_idx == 110 or episode_idx == 118 \\\n",
        "          or episode_idx == 119 or episode_idx == 120 or episode_idx == 121 or episode_idx == 122 or episode_idx == 126 or episode_idx == 152:\n",
        "            last_frames_to_chop = 38\n",
        "        elif episode_idx == 11 or episode_idx == 14 or episode_idx == 17 or episode_idx == 25 or episode_idx == 37 or episode_idx == 132:\n",
        "            last_frames_to_chop = 32\n",
        "        elif episode_idx == 15 or episode_idx == 30 or episode_idx == 38 or episode_idx == 40 or episode_idx == 41 or episode_idx == 42 \\\n",
        "          or episode_idx == 49 or episode_idx == 51 or episode_idx == 52 or episode_idx == 56 or episode_idx == 57 or episode_idx == 65 \\\n",
        "          or episode_idx == 68 or episode_idx == 70 or episode_idx == 74 or episode_idx == 78 or episode_idx == 79 or episode_idx == 81 \\\n",
        "          or episode_idx == 82 or episode_idx == 83 or episode_idx == 84 or episode_idx == 91 or episode_idx == 104 or episode_idx == 105 \\\n",
        "          or episode_idx == 106 or episode_idx == 127 or episode_idx == 144 or episode_idx == 146 or episode_idx == 147 or episode_idx == 148 \\\n",
        "            or episode_idx == 149:\n",
        "            last_frames_to_chop = 30\n",
        "        elif episode_idx == 137:\n",
        "            last_frames_to_chop = 24\n",
        "        elif episode_idx == 44 or episode_idx == 162 or episode_idx == 164:\n",
        "            last_frames_to_chop = 25\n",
        "        elif episode_idx == 129:\n",
        "            last_frames_to_chop = 18\n",
        "        elif episode_idx > 129 :\n",
        "            last_frames_to_chop = 28\n",
        "        elif episode_idx < 129:\n",
        "            last_frames_to_chop = 35\n",
        "        \n",
        "        try:\n",
        "            episode_data = process_episode_folder(episode_folder, episode_idx, global_index_offset, last_frames_to_chop)\n",
        "            all_episodes_data.append(episode_data)\n",
        "            \n",
        "            # Update global index offset for the next episode\n",
        "            global_index_offset += episode_data.num_of_frames\n",
        "            #global_index_offset -= last_frames_to_chop\n",
        "            \n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing episode {episode_idx}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Create final output files after processing all episodes\n",
        "    if all_episodes_data:\n",
        "        # Only create tasks parquet for the first episode\n",
        "        create_tasks_parquet(OUTPUT_FOLDER, 'pick_and_place')\n",
        "        \n",
        "        # Create episodes parquet index for all episodes\n",
        "        for _, episode_idx in episode_folders:\n",
        "            create_episodes_parquet_index(OUTPUT_FOLDER, episode_idx)\n",
        "        \n",
        "        update_total_frames_from_episodes(OUTPUT_FOLDER)\n",
        "        \n",
        "        compute_and_save_dataset_stats(OUTPUT_FOLDER)\n",
        "        \n",
        "    else:\n",
        "        print(\"No episodes were successfully processed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "\n",
        "!hf upload \\\n",
        "  'ISDept/piper_arm' \\\n",
        "  /Users/eddyma/DEV/Github/lerobot-piper/src/output \\\n",
        "  --repo-type dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Webcam inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "!python webcam_inference.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video Inference - Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video inference - SmolVLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python extract_joint_positions.py\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_joint_positions(json_file_path, title, start_frame_index=0):\n",
        "    \"\"\"\n",
        "    Plots joint positions from a JSON file, starting from a specified frame index.\n",
        "    Handles both inference results format and joint positions format.\n",
        "\n",
        "    Parameters:\n",
        "    json_file_path (str): Path to the JSON file.\n",
        "    title (str): Title for the plot.\n",
        "    start_frame_index (int): The frame index from which to start plotting. Defaults to 0 (the beginning).\n",
        "    \"\"\"\n",
        "    # Read the JSON file\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Check if this is inference results format (list of objects with 'result' key)\n",
        "    # or joint positions format (list of arrays)\n",
        "    if isinstance(data, list) and len(data) > 0:\n",
        "        # This is joint positions format (list of arrays)\n",
        "        # For this format, we'll just plot all data starting from start_frame_index\n",
        "        if start_frame_index >= len(data):\n",
        "            print(f\"No data found starting from frame index {start_frame_index}.\")\n",
        "            return\n",
        "        \n",
        "        # Extract joint positions from start_frame_index onward\n",
        "        filtered_data = data[start_frame_index:]\n",
        "        frame_indices = list(range(start_frame_index, start_frame_index + len(filtered_data)))\n",
        "        print(f\"Frames plotted: {len(frame_indices)} (from index {min(frame_indices)} to {max(frame_indices)})\")\n",
        "        \n",
        "        # Initialize lists for each joint\n",
        "        joints = [[] for _ in range(7)]  # 6 joints + 1 gripper\n",
        "        \n",
        "        # Extract joint positions for each frame in the filtered data\n",
        "        for action in filtered_data:\n",
        "            for i in range(7):  # 6 joints + 1 gripper\n",
        "                joints[i].append(action[i])\n",
        "\n",
        "    \n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 4)) # Slightly larger figure for clarity\n",
        "    \n",
        "    # Joint names\n",
        "    joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']\n",
        "    \n",
        "    # Plot each joint with a different color\n",
        "    for i in range(7):\n",
        "        plt.plot(frame_indices, joints[i], label=joint_names[i], marker='o', markersize=3, linewidth=1.5)\n",
        "    \n",
        "    # Add labels and title\n",
        "    plt.xlabel('Frame Index')\n",
        "    plt.ylabel('Joint Position')\n",
        "    plt.title(f\"{title} (Starting from frame {start_frame_index})\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') # Legend outside plot\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions Training')\n",
        "plot_joint_positions('temp/data_20251128_095915_gt.json', 'Ground Truth Joint Positions')\n",
        "plot_joint_positions('temp/inference_actions_close_loop.json', 'Predicted Joint Positions Closed Loop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
        "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
        "# Comment out the old pretrained model path\n",
        " # pretrained_policy_path = \"lerobot/diffusion_pusht\"\n",
        "# Use your newly trained model path instead\n",
        "pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
        "policy = DiffusionPolicy.from_pretrained(\"ISdept/piper_arm\")\n",
        "\n",
        "print(policy.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated plotting functionality using the new plotting utility\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve()))\n",
        "\n",
        "from plotting_utils import plot_joint_positions\n",
        "\n",
        "# Plot the data using the improved function that handles both file formats\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions - Episode 1')\n",
        "plot_joint_positions('temp/metadata_20251113_080958_gt.json', 'Ground Truth Joint Positions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python inspect_local_parquet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-train \\\n",
        "  --dataset.repo_id=ISdept/piper_arm \\\n",
        "  --policy.type=diffusion \\\n",
        "  --output_dir=outputs/train/output_diff3 \\\n",
        "  --job_name=pick_and_place \\\n",
        "  --policy.device=cuda \\\n",
        "  --policy.repo_id=ISdept/piper_arm \\\n",
        "  --wandb.enable=false \\\n",
        "  --dataset.revision=\"main\" \\\n",
        "  --dataset.image_transforms.enable=True \\\n",
        "  --policy.use_separate_rgb_encoder_per_camera=True \\\n",
        "  --policy.crop_shape=[400,400] \\\n",
        "  --save_checkpoint=True \\\n",
        "  --save_freq=2000 \\\n",
        "  \\\n",
        "  --steps=25000 \\\n",
        "  --policy.n_obs_steps=10 \\\n",
        "  --policy.horizon=24 \\\n",
        "  --batch_size=3 \\\n",
        "  --num_workers=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-eval \\\n",
        "  --policy.repo_id=\"ISdept/piper_arm\" \\\n",
        "  --policy.type=\"diffusion\" \\\n",
        "  --policy.device=\"mps\" \\\n",
        "  --env.type=\"aloha\" \\\n",
        "  --eval.n_episodes=10 \\\n",
        "  --output_dir=\"outputs/inference/piper_arm_eval\" \\\n",
        "  --job_name=\"piper_arm_diffusion_eval\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-dataset-viz \\\n",
        "    --repo-id ISdept/piper_arm \\\n",
        "    --episode-index 001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0199, -0.3549, -2.1588])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "(torch.rand(1).item() - 0.5) * 0.01\n",
        "\n",
        "base = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "torch.randn_like(base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frame_time = 0.1\n",
        "[i * frame_time for i in range(24)]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "for_lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
