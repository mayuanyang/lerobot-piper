{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch lerobot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lerobot.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers num2words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add parent directory to path to import train module\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "from train_smolvla import train\n",
        "\n",
        "print(\"\\nStarting training process...\")\n",
        "print(\"Note: We'll use a public dataset for training as our sample is too small\")\n",
        "\n",
        "# Create a temporary directory for training output\n",
        "train_output_dir = Path('model_output')\n",
        "\n",
        "print(f\"Training output will be saved to: {train_output_dir}\")\n",
        "\n",
        "#train(output_dir=str(train_output_dir), dataset_id=\"ISdept/piper_arm\")\n",
        "train(output_dir=str(train_output_dir), dataset_id=\"ISdept/piper_arm\", model_id=\"ISdept/smolvla-piper\", resume_from_checkpoint=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# Add the src directory to the path so we can import prepare_dataset\n",
        "from data_processing.prepare_dataset import process_session, create_tasks_parquet, create_episodes_parquet_index, update_total_frames_from_episodes, compute_and_save_dataset_stats\n",
        "from data_processing.episode_data import EpisodeData, CameraData\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "ROOT_FOLDER = Path(\"data/piper_training_data/\")  # Root folder containing episode subfolders\n",
        "OUTPUT_FOLDER = Path(\"output/\")  # Output folder for processed dataset\n",
        "REPO_ID = \"ISDept/piper_arm\"  # Your desired Hugging Face repo ID\n",
        "# ---------------------\n",
        "\n",
        "def find_episode_folders(root_folder):\n",
        "    \"\"\"Find all episode folders with naming convention episode1, episode2, etc.\"\"\"\n",
        "    episode_folders = []\n",
        "    pattern = re.compile(r'^episode(\\d+)$', re.IGNORECASE)\n",
        "    \n",
        "    for item in root_folder.iterdir():\n",
        "        if item.is_dir():\n",
        "            match = pattern.match(item.name)\n",
        "            if match:\n",
        "                episode_folders.append((item, int(match.group(1))))\n",
        "    \n",
        "    # Sort by episode number\n",
        "    episode_folders.sort(key=lambda x: x[1])\n",
        "    return episode_folders\n",
        "\n",
        "def find_json_and_videos(episode_folder):\n",
        "    \"\"\"Find JSON file and video files in the episode folder.\"\"\"\n",
        "    json_files = list(episode_folder.glob(\"*.json\"))\n",
        "    if not json_files:\n",
        "        raise FileNotFoundError(f\"No JSON file found in {episode_folder}\")\n",
        "    if len(json_files) > 1:\n",
        "        print(f\"Warning: Multiple JSON files found in {episode_folder}, using {json_files[0]}\")\n",
        "    \n",
        "    json_path = json_files[0]\n",
        "    \n",
        "    # Find video files (assuming common video extensions)\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
        "    video_files = []\n",
        "    for ext in video_extensions:\n",
        "        video_files.extend(episode_folder.glob(f\"*{ext}\"))\n",
        "    \n",
        "    return json_path, video_files\n",
        "\n",
        "def get_camera_name_from_video_path(video_path):\n",
        "    \"\"\"Determine camera name based on video filename content.\"\"\"\n",
        "    filename = video_path.stem.lower()\n",
        "    if 'front' in filename:\n",
        "        return 'front'\n",
        "    elif 'right' in filename:\n",
        "        return 'right'\n",
        "    elif 'gripper' in filename:\n",
        "        return 'gripper'\n",
        "    else:\n",
        "        # Fallback: use the last part of filename after underscore\n",
        "        return video_path.stem.split('_')[-1]\n",
        "      \n",
        "def process_episode_folder(episode_folder, episode_idx, global_index_offset, last_frames_to_chop):\n",
        "    \"\"\"Process a single episode folder.\"\"\"\n",
        "    json_path, video_files = find_json_and_videos(episode_folder)\n",
        "    \n",
        "    # Create CameraData objects from video files\n",
        "    cameras_list = []\n",
        "    for video_path in video_files:\n",
        "        # Extract camera name from filename (you might want to customize this logic)\n",
        "        camera_name = get_camera_name_from_video_path(video_path)\n",
        "        cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "    \n",
        "    episode_data = EpisodeData(\n",
        "        joint_data_json_path=str(json_path), \n",
        "        episode_index=episode_idx, \n",
        "        fps=10, \n",
        "        global_index_offset=global_index_offset, \n",
        "        cameras=cameras_list,\n",
        "        folder = episode_folder,\n",
        "        task_description = \"Pick up the cube and place it into the container.\"\n",
        "    )\n",
        "    \n",
        "    # Process the first episode differently to create initial files\n",
        "    is_first_episode = (episode_idx == 1)\n",
        "    num_of_frames = process_session(episode_data, OUTPUT_FOLDER, is_first_episode, last_frames_to_chop)\n",
        "    episode_data.num_of_frames = num_of_frames\n",
        "    return episode_data\n",
        "\n",
        "def main():\n",
        "    # Find all episode folders\n",
        "    episode_folders = find_episode_folders(ROOT_FOLDER)\n",
        "    \n",
        "    if not episode_folders:\n",
        "        print(f\"No episode folders found in {ROOT_FOLDER}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Found {len(episode_folders)} episode folders\")\n",
        "    \n",
        "    # First, collect all episode data without processing to compute global statistics\n",
        "    print(\"Collecting episode data for processing...\")\n",
        "    all_episodes_data = []\n",
        "    \n",
        "    # Store episode-specific parameters\n",
        "    episode_params = {}\n",
        "    \n",
        "    last_frames_to_chop = 5  # Default value\n",
        "    for episode_folder, episode_idx in episode_folders:    \n",
        "        # if episode_idx == 3:\n",
        "        #     last_frames_to_chop = 42\n",
        "        # elif episode_idx == 7 or episode_idx == 32 or episode_idx == 46 or episode_idx == 76 or episode_idx == 87 or episode_idx == 88 \\\n",
        "        #   or episode_idx ==  89 or episode_idx == 102 or episode_idx == 103 or episode_idx == 108 or episode_idx == 110 or episode_idx == 118 \\\n",
        "        #   or episode_idx == 119 or episode_idx == 120 or episode_idx == 121 or episode_idx == 122 or episode_idx == 126 or episode_idx == 152:\n",
        "        #     last_frames_to_chop = 38\n",
        "        # elif episode_idx == 11 or episode_idx == 14 or episode_idx == 17 or episode_idx == 25 or episode_idx == 37 or episode_idx == 132:\n",
        "        #     last_frames_to_chop = 32\n",
        "        # elif episode_idx == 15 or episode_idx == 30 or episode_idx == 38 or episode_idx == 40 or episode_idx == 41 or episode_idx == 42 \\\n",
        "        #   or episode_idx == 49 or episode_idx == 51 or episode_idx == 52 or episode_idx == 56 or episode_idx == 57 or episode_idx == 65 \\\n",
        "        #   or episode_idx == 68 or episode_idx == 70 or episode_idx == 74 or episode_idx == 78 or episode_idx == 79 or episode_idx == 81 \\\n",
        "        #   or episode_idx == 82 or episode_idx == 83 or episode_idx == 84 or episode_idx == 91 or episode_idx == 104 or episode_idx == 105 \\\n",
        "        #   or episode_idx == 106 or episode_idx == 127 or episode_idx == 144 or episode_idx == 146 or episode_idx == 147 or episode_idx == 148 \\\n",
        "        #     or episode_idx == 149:\n",
        "        #     last_frames_to_chop = 30\n",
        "        # elif episode_idx == 137:\n",
        "        #     last_frames_to_chop = 24\n",
        "        # elif episode_idx == 44 or episode_idx == 162 or episode_idx == 164:\n",
        "        #     last_frames_to_chop = 25\n",
        "        # elif episode_idx == 129:\n",
        "        #     last_frames_to_chop = 18\n",
        "        # elif episode_idx > 129 :\n",
        "        #     last_frames_to_chop = 28\n",
        "        # elif episode_idx < 129:\n",
        "        #     last_frames_to_chop = 35\n",
        "        \n",
        "        # Store parameters for this episode\n",
        "        episode_params[episode_idx] = {\n",
        "            'last_frames_to_chop': last_frames_to_chop\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            # Create episode data object (without processing yet)\n",
        "            json_path, video_files = find_json_and_videos(episode_folder)\n",
        "            \n",
        "            # Create CameraData objects from video files\n",
        "            cameras_list = []\n",
        "            for video_path in video_files:\n",
        "                # Extract camera name from filename (you might want to customize this logic)\n",
        "                camera_name = get_camera_name_from_video_path(video_path)\n",
        "                cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "            \n",
        "            episode_data = EpisodeData(\n",
        "                joint_data_json_path=str(json_path), \n",
        "                episode_index=episode_idx, \n",
        "                fps=10, \n",
        "                global_index_offset=0,  # Will be updated during processing\n",
        "                cameras=cameras_list,\n",
        "                folder = episode_folder,\n",
        "                task_description = \"Pick up the cube and place it into the container.\",\n",
        "                last_frames_to_chop = last_frames_to_chop\n",
        "            )\n",
        "            \n",
        "            all_episodes_data.append(episode_data)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error collecting data from episode {episode_idx}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Now process all episodes\n",
        "    print(\"Processing episodes...\")\n",
        "    processed_episodes_data = []\n",
        "    global_index_offset = 0\n",
        "    \n",
        "    for episode in all_episodes_data:\n",
        "                \n",
        "        episode_folder = episode.folder\n",
        "        episode_idx = episode.episode_index\n",
        "        last_frames_to_chop = episode.last_frames_to_chop\n",
        "        \n",
        "        print(f\"Processing episode {episode_idx} in folder {episode_folder}\")\n",
        "        \n",
        "        try:\n",
        "            # Create episode data with correct global index offset\n",
        "            json_path, video_files = find_json_and_videos(episode_folder)\n",
        "            \n",
        "            # Create CameraData objects from video files\n",
        "            cameras_list = []\n",
        "            for video_path in video_files:\n",
        "                # Extract camera name from filename (you might want to customize this logic)\n",
        "                camera_name = get_camera_name_from_video_path(video_path)\n",
        "                cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "            \n",
        "                        \n",
        "            # Process the first episode differently to create initial files\n",
        "            is_first_episode = (episode_idx == 1)\n",
        "            num_of_frames = process_session(episode, OUTPUT_FOLDER, is_first_episode, last_frames_to_chop)\n",
        "            episode.num_of_frames = num_of_frames\n",
        "            \n",
        "            # Update global index offset for the next episode\n",
        "            global_index_offset += episode.num_of_frames\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing episode {episode_idx}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Create final output files after processing all episodes\n",
        "    if all_episodes_data:\n",
        "        # Only create tasks parquet for the first episode\n",
        "        create_tasks_parquet(OUTPUT_FOLDER, 'pick_and_place')\n",
        "        \n",
        "        # Create episodes parquet index for all episodes\n",
        "        for _, episode_idx in episode_folders:\n",
        "            create_episodes_parquet_index(OUTPUT_FOLDER, episode_idx)\n",
        "        \n",
        "        update_total_frames_from_episodes(OUTPUT_FOLDER)\n",
        "        \n",
        "        # Compute and save dataset statistics\n",
        "        compute_and_save_dataset_stats(OUTPUT_FOLDER)\n",
        "        \n",
        "        print(\"Dataset preparation completed successfully!\")\n",
        "    else:\n",
        "        print(\"No episodes were successfully processed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/ISdept/piper_arm/tree/main/.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "\n",
        "!hf upload \\\n",
        "  'ISdept/piper_arm' \\\n",
        "  /Users/eddyma/DEV/Github/lerobot-piper/src/output \\\n",
        "  --repo-type dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Webcam inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "!python webcam_inference.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video Inference - Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video inference - SmolVLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python extract_joint_positions.py\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_joint_positions(json_file_path, title, start_frame_index=0):\n",
        "    \"\"\"\n",
        "    Plots joint positions from a JSON file, starting from a specified frame index.\n",
        "    Handles both inference results format and joint positions format.\n",
        "\n",
        "    Parameters:\n",
        "    json_file_path (str): Path to the JSON file.\n",
        "    title (str): Title for the plot.\n",
        "    start_frame_index (int): The frame index from which to start plotting. Defaults to 0 (the beginning).\n",
        "    \"\"\"\n",
        "    # Read the JSON file\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Check if this is inference results format (list of objects with 'result' key)\n",
        "    # or joint positions format (list of arrays)\n",
        "    if isinstance(data, list) and len(data) > 0:\n",
        "        # This is joint positions format (list of arrays)\n",
        "        # For this format, we'll just plot all data starting from start_frame_index\n",
        "        if start_frame_index >= len(data):\n",
        "            print(f\"No data found starting from frame index {start_frame_index}.\")\n",
        "            return\n",
        "        \n",
        "        # Extract joint positions from start_frame_index onward\n",
        "        filtered_data = data[start_frame_index:]\n",
        "        frame_indices = list(range(start_frame_index, start_frame_index + len(filtered_data)))\n",
        "        print(f\"Frames plotted: {len(frame_indices)} (from index {min(frame_indices)} to {max(frame_indices)})\")\n",
        "        \n",
        "        # Initialize lists for each joint\n",
        "        joints = [[] for _ in range(7)]  # 6 joints + 1 gripper\n",
        "        \n",
        "        # Extract joint positions for each frame in the filtered data\n",
        "        for action in filtered_data:\n",
        "            for i in range(7):  # 6 joints + 1 gripper\n",
        "                joints[i].append(action[i])\n",
        "\n",
        "    \n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 4)) # Slightly larger figure for clarity\n",
        "    \n",
        "    # Joint names\n",
        "    joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']\n",
        "    \n",
        "    # Plot each joint with a different color\n",
        "    for i in range(7):\n",
        "        plt.plot(frame_indices, joints[i], label=joint_names[i], marker='o', markersize=3, linewidth=1.5)\n",
        "    \n",
        "    # Add labels and title\n",
        "    plt.xlabel('Frame Index')\n",
        "    plt.ylabel('Joint Position')\n",
        "    plt.title(f\"{title} (Starting from frame {start_frame_index})\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') # Legend outside plot\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions Training')\n",
        "plot_joint_positions('temp/data_20251128_095915_gt.json', 'Ground Truth Joint Positions')\n",
        "plot_joint_positions('temp/inference_actions_close_loop.json', 'Predicted Joint Positions Closed Loop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
        "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
        "# Comment out the old pretrained model path\n",
        " # pretrained_policy_path = \"lerobot/diffusion_pusht\"\n",
        "# Use your newly trained model path instead\n",
        "pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
        "policy = DiffusionPolicy.from_pretrained(\"ISdept/piper_arm\")\n",
        "\n",
        "print(policy.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated plotting functionality using the new plotting utility\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve()))\n",
        "\n",
        "from plotting_utils import plot_joint_positions\n",
        "\n",
        "# Plot the data using the improved function that handles both file formats\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions - Episode 1')\n",
        "plot_joint_positions('temp/metadata_20251113_080958_gt.json', 'Ground Truth Joint Positions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python inspect_local_parquet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-train \\\n",
        "  --dataset.repo_id=ISdept/piper_arm \\\n",
        "  --policy.type=diffusion \\\n",
        "  --output_dir=outputs/train/output_diff3 \\\n",
        "  --job_name=pick_and_place \\\n",
        "  --policy.device=cuda \\\n",
        "  --policy.repo_id=ISdept/piper_arm \\\n",
        "  --wandb.enable=false \\\n",
        "  --dataset.revision=\"main\" \\\n",
        "  --dataset.image_transforms.enable=True \\\n",
        "  --policy.use_separate_rgb_encoder_per_camera=True \\\n",
        "  --policy.crop_shape=[400,400] \\\n",
        "  --save_checkpoint=True \\\n",
        "  --save_freq=2000 \\\n",
        "  \\\n",
        "  --steps=25000 \\\n",
        "  --policy.n_obs_steps=10 \\\n",
        "  --policy.horizon=24 \\\n",
        "  --batch_size=3 \\\n",
        "  --num_workers=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-eval \\\n",
        "  --policy.repo_id=\"ISdept/piper_arm\" \\\n",
        "  --policy.type=\"diffusion\" \\\n",
        "  --policy.device=\"mps\" \\\n",
        "  --env.type=\"aloha\" \\\n",
        "  --eval.n_episodes=10 \\\n",
        "  --output_dir=\"outputs/inference/piper_arm_eval\" \\\n",
        "  --job_name=\"piper_arm_diffusion_eval\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-dataset-viz \\\n",
        "    --repo-id ISdept/piper_arm \\\n",
        "    --episode-index 085 \\\n",
        "    --root /Users/eddyma/DEV/Github/lerobot-piper/src/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: lerobot-imgtransform-viz [-h] [--config_path str] [--repo_id str]\n",
            "                                [--root str] [--episodes str]\n",
            "                                [--image_transforms str]\n",
            "                                [--image_transforms.enable str]\n",
            "                                [--image_transforms.max_num_transforms str]\n",
            "                                [--image_transforms.random_order str]\n",
            "                                [--image_transforms.tfs str] [--revision str]\n",
            "                                [--use_imagenet_stats str]\n",
            "                                [--video_backend str] [--streaming str]\n",
            "lerobot-imgtransform-viz: error: unrecognized arguments: --repo-id=ISdept/piper_arm --output-dir=transform_examples --n-examples=5\n"
          ]
        }
      ],
      "source": [
        "!lerobot-imgtransform-viz \\\n",
        "  --repo-id=ISdept/piper_arm \\\n",
        "  --output-dir=transform_examples \\\n",
        "  --n-examples=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.1, 0.0]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obs_temporal_window = [ -i * 0.1 for i in range(2) ][::-1]\n",
        "obs_temporal_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "!python ../convert.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
        "\n",
        "dataset = LeRobotDataset(\"ISdept/piper_arm\", force_cache_sync=True, revision=\"main\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "dataset.hf_dataset\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        num_workers=0,\n",
        "        batch_size=20,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "idx = 0\n",
        "for batch in train_dataloader:\n",
        "    #print(batch)\n",
        "    print(batch['episode_index'], len(batch['observation.state']))\n",
        "    print('---', idx)\n",
        "    idx += 1\n",
        "    if idx >= 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 0.7408, 0.5488, 0.4066, 0.3012, 0.2231, 0.1653, 0.1225])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0.2850, 0.2112, 0.1564, 0.1159, 0.0859, 0.0636, 0.0471, 0.0349])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "weights = torch.exp(-0.3 * torch.arange(8))\n",
        "print(weights)\n",
        "weights = weights / weights.sum() # Normalize\n",
        "weights"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "for_lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
