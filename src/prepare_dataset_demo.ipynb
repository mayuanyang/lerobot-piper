{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch lerobot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lerobot.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers num2words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add parent directory to path to import train module\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "from train_smolvla import train\n",
        "\n",
        "print(\"\\nStarting training process...\")\n",
        "print(\"Note: We'll use a public dataset for training as our sample is too small\")\n",
        "\n",
        "# Create a temporary directory for training output\n",
        "train_output_dir = Path('model_output')\n",
        "\n",
        "print(f\"Training output will be saved to: {train_output_dir}\")\n",
        "\n",
        "train(output_dir=str(train_output_dir), dataset_id=\"ISdept/piper_arm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 125 episode folders\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 150/150 [00:00<00:00, 14436.90 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 943.39ba/s]\n",
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 29978.40 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1368.45ba/s]\n",
            "Casting the dataset: 100%|██████████| 137/137 [00:00<00:00, 45410.12 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 960.89ba/s]\n",
            "Casting the dataset: 100%|██████████| 108/108 [00:00<00:00, 32085.62 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 963.54ba/s]\n",
            "Casting the dataset: 100%|██████████| 112/112 [00:00<00:00, 38810.48 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1222.12ba/s]\n",
            "Casting the dataset: 100%|██████████| 112/112 [00:00<00:00, 40696.70 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1607.63ba/s]\n",
            "Casting the dataset: 100%|██████████| 129/129 [00:00<00:00, 45845.21 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1534.13ba/s]\n",
            "Casting the dataset: 100%|██████████| 124/124 [00:00<00:00, 41524.45 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1022.50ba/s]\n",
            "Casting the dataset: 100%|██████████| 208/208 [00:00<00:00, 73578.07 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1290.56ba/s]\n",
            "Casting the dataset: 100%|██████████| 106/106 [00:00<00:00, 34270.89 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1293.74ba/s]\n",
            "Casting the dataset: 100%|██████████| 88/88 [00:00<00:00, 29419.64 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1024.75ba/s]\n",
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 28631.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1216.45ba/s]\n",
            "Casting the dataset: 100%|██████████| 93/93 [00:00<00:00, 30088.73 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1009.22ba/s]\n",
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 29105.83 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1084.64ba/s]\n",
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 26390.99 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1140.07ba/s]\n",
            "Casting the dataset: 100%|██████████| 85/85 [00:00<00:00, 24660.43 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1055.70ba/s]\n",
            "Casting the dataset: 100%|██████████| 99/99 [00:00<00:00, 29813.05 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 639.77ba/s]\n",
            "Casting the dataset: 100%|██████████| 108/108 [00:00<00:00, 33739.37 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1381.07ba/s]\n",
            "Casting the dataset: 100%|██████████| 103/103 [00:00<00:00, 31868.79 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1213.63ba/s]\n",
            "Casting the dataset: 100%|██████████| 89/89 [00:00<00:00, 27649.29 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1136.05ba/s]\n",
            "Casting the dataset: 100%|██████████| 106/106 [00:00<00:00, 36278.76 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1137.90ba/s]\n",
            "Casting the dataset: 100%|██████████| 105/105 [00:00<00:00, 39122.49 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1243.86ba/s]\n",
            "Casting the dataset: 100%|██████████| 117/117 [00:00<00:00, 45505.71 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1308.68ba/s]\n",
            "Casting the dataset: 100%|██████████| 105/105 [00:00<00:00, 38628.36 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1272.16ba/s]\n",
            "Casting the dataset: 100%|██████████| 135/135 [00:00<00:00, 43775.11 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1142.86ba/s]\n",
            "Casting the dataset: 100%|██████████| 101/101 [00:00<00:00, 32589.02 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1190.55ba/s]\n",
            "Casting the dataset: 100%|██████████| 121/121 [00:00<00:00, 37811.86 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1188.52ba/s]\n",
            "Casting the dataset: 100%|██████████| 110/110 [00:00<00:00, 40042.83 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1424.70ba/s]\n",
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 30714.47 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1082.12ba/s]\n",
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 28364.36 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1067.25ba/s]\n",
            "Casting the dataset: 100%|██████████| 95/95 [00:00<00:00, 30033.83 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 932.90ba/s]\n",
            "Casting the dataset: 100%|██████████| 122/122 [00:00<00:00, 43280.48 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1231.81ba/s]\n",
            "Casting the dataset: 100%|██████████| 107/107 [00:00<00:00, 36931.41 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1203.53ba/s]\n",
            "Casting the dataset: 100%|██████████| 92/92 [00:00<00:00, 34060.90 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1475.31ba/s]\n",
            "Casting the dataset: 100%|██████████| 94/94 [00:00<00:00, 27663.81 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1148.18ba/s]\n",
            "Casting the dataset: 100%|██████████| 96/96 [00:00<00:00, 29294.52 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1122.07ba/s]\n",
            "Casting the dataset: 100%|██████████| 87/87 [00:00<00:00, 21534.64 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 944.24ba/s]\n",
            "Casting the dataset: 100%|██████████| 80/80 [00:00<00:00, 26611.49 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1025.75ba/s]\n",
            "Casting the dataset: 100%|██████████| 113/113 [00:00<00:00, 31128.09 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1086.89ba/s]\n",
            "Casting the dataset: 100%|██████████| 86/86 [00:00<00:00, 26874.55 examples/s]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1135.13ba/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo episodes were successfully processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[1], line 110\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode_folder, episode_idx \u001b[38;5;129;01min\u001b[39;00m episode_folders:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         episode_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_episode_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_index_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_frames_to_chop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m         all_episodes_data\u001b[38;5;241m.\u001b[39mappend(episode_data)\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;66;03m# Update global index offset for the next episode\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[1], line 87\u001b[0m, in \u001b[0;36mprocess_episode_folder\u001b[0;34m(episode_folder, episode_idx, global_index_offset, last_frames_to_chop)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Process the first episode differently to create initial files\u001b[39;00m\n\u001b[1;32m     86\u001b[0m is_first_episode \u001b[38;5;241m=\u001b[39m (episode_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m num_of_frames \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first_episode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_frames_to_chop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m episode_data\u001b[38;5;241m.\u001b[39mnum_of_frames \u001b[38;5;241m=\u001b[39m num_of_frames\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m episode_data\n",
            "File \u001b[0;32m~/DEV/Github/lerobot-piper/src/data_processing/prepare_dataset.py:667\u001b[0m, in \u001b[0;36mprocess_session\u001b[0;34m(episode_data, output_dir, is_first_episode, last_frames_to_chop)\u001b[0m\n\u001b[1;32m    662\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# Note: We assume generate_video_files either handles chopping internally \u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# (if source is a video) or is called BEFORE chopping the images/joints.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# For now, we assume video files contain all frames and only the tabular data is chopped.\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m \u001b[43mgenerate_video_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_frames_to_chop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# Pass the chop value to meta file generator\u001b[39;00m\n\u001b[1;32m    670\u001b[0m generate_meta_files(output_dir, episode_data, json_data, is_first_episode, last_frames_to_chop)   \n",
            "File \u001b[0;32m~/DEV/Github/lerobot-piper/src/data_processing/prepare_dataset.py:334\u001b[0m, in \u001b[0;36mgenerate_video_files\u001b[0;34m(output_dir, episode_data, json_data, last_frames_to_chop)\u001b[0m\n\u001b[1;32m    331\u001b[0m video_file_path \u001b[38;5;241m=\u001b[39m Path(camera_data\u001b[38;5;241m.\u001b[39mvideo_path)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m video_file_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m video_file_path\u001b[38;5;241m.\u001b[39msuffix\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# If it's a video file, we need to chop it to match the effective frame count\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[43mchop_video_to_frame_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_num_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m video_file_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# For other file types, just copy\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy(video_file_path, output_video_path)\n",
            "File \u001b[0;32m~/DEV/Github/lerobot-piper/src/data_processing/prepare_dataset.py:359\u001b[0m, in \u001b[0;36mchop_video_to_frame_count\u001b[0;34m(input_video_path, output_video_path, target_frame_count, fps)\u001b[0m\n\u001b[1;32m    348\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(input_video_path),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mstr\u001b[39m(output_video_path)\n\u001b[1;32m    356\u001b[0m ]\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ WARNING: Failed to chop video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_frame_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m frames: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/subprocess.py:1796\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1794\u001b[0m     fds_to_keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(pass_fds)\n\u001b[1;32m   1795\u001b[0m     fds_to_keep\u001b[38;5;241m.\u001b[39madd(errpipe_write)\n\u001b[0;32m-> 1796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[43m_posixsubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfork_exec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfds_to_keep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrpipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrpipe_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_child_created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;66;03m# be sure the FD is closed no matter what\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# Add the src directory to the path so we can import prepare_dataset\n",
        "from data_processing.prepare_dataset import process_session, create_tasks_parquet, create_episodes_parquet_index, update_total_frames_from_episodes, compute_and_save_dataset_stats\n",
        "from data_processing.episode_data import EpisodeData, CameraData\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "ROOT_FOLDER = Path(\"data/piper_training_data/\")  # Root folder containing episode subfolders\n",
        "OUTPUT_FOLDER = Path(\"output/\")  # Output folder for processed dataset\n",
        "REPO_ID = \"ISDept/piper_arm\"  # Your desired Hugging Face repo ID\n",
        "# ---------------------\n",
        "\n",
        "def find_episode_folders(root_folder):\n",
        "    \"\"\"Find all episode folders with naming convention episode1, episode2, etc.\"\"\"\n",
        "    episode_folders = []\n",
        "    pattern = re.compile(r'^episode(\\d+)$', re.IGNORECASE)\n",
        "    \n",
        "    for item in root_folder.iterdir():\n",
        "        if item.is_dir():\n",
        "            match = pattern.match(item.name)\n",
        "            if match:\n",
        "                episode_folders.append((item, int(match.group(1))))\n",
        "    \n",
        "    # Sort by episode number\n",
        "    episode_folders.sort(key=lambda x: x[1])\n",
        "    return episode_folders\n",
        "\n",
        "def find_json_and_videos(episode_folder):\n",
        "    \"\"\"Find JSON file and video files in the episode folder.\"\"\"\n",
        "    json_files = list(episode_folder.glob(\"*.json\"))\n",
        "    if not json_files:\n",
        "        raise FileNotFoundError(f\"No JSON file found in {episode_folder}\")\n",
        "    if len(json_files) > 1:\n",
        "        print(f\"Warning: Multiple JSON files found in {episode_folder}, using {json_files[0]}\")\n",
        "    \n",
        "    json_path = json_files[0]\n",
        "    \n",
        "    # Find video files (assuming common video extensions)\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
        "    video_files = []\n",
        "    for ext in video_extensions:\n",
        "        video_files.extend(episode_folder.glob(f\"*{ext}\"))\n",
        "    \n",
        "    return json_path, video_files\n",
        "\n",
        "def get_camera_name_from_video_path(video_path):\n",
        "    \"\"\"Determine camera name based on video filename content.\"\"\"\n",
        "    filename = video_path.stem.lower()\n",
        "    if 'front' in filename:\n",
        "        return 'front'\n",
        "    elif 'right' in filename:\n",
        "        return 'right'\n",
        "    elif 'gripper' in filename:\n",
        "        return 'gripper'\n",
        "    else:\n",
        "        # Fallback: use the last part of filename after underscore\n",
        "        return video_path.stem.split('_')[-1]\n",
        "      \n",
        "def process_episode_folder(episode_folder, episode_idx, global_index_offset, last_frames_to_chop):\n",
        "    \"\"\"Process a single episode folder.\"\"\"\n",
        "    json_path, video_files = find_json_and_videos(episode_folder)\n",
        "    \n",
        "    # Create CameraData objects from video files\n",
        "    cameras_list = []\n",
        "    for video_path in video_files:\n",
        "        # Extract camera name from filename (you might want to customize this logic)\n",
        "        camera_name = get_camera_name_from_video_path(video_path)\n",
        "        cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "    \n",
        "    episode_data = EpisodeData(\n",
        "        joint_data_json_path=str(json_path), \n",
        "        episode_index=episode_idx, \n",
        "        fps=10, \n",
        "        global_index_offset=global_index_offset, \n",
        "        cameras=cameras_list,\n",
        "        folder = episode_folder,\n",
        "        task_description = \"Pick up the cube and place it into the container.\"\n",
        "    )\n",
        "    \n",
        "    # Process the first episode differently to create initial files\n",
        "    is_first_episode = (episode_idx == 1)\n",
        "    num_of_frames = process_session(episode_data, OUTPUT_FOLDER, is_first_episode, last_frames_to_chop)\n",
        "    episode_data.num_of_frames = num_of_frames\n",
        "    return episode_data\n",
        "\n",
        "def main():\n",
        "    # Find all episode folders\n",
        "    episode_folders = find_episode_folders(ROOT_FOLDER)\n",
        "    \n",
        "    if not episode_folders:\n",
        "        print(f\"No episode folders found in {ROOT_FOLDER}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Found {len(episode_folders)} episode folders\")\n",
        "    \n",
        "    last_frames_to_chop = 30\n",
        "    global_index_offset = 0\n",
        "    all_episodes_data = []\n",
        "    \n",
        "    \n",
        "    # Process each episode folder\n",
        "    for episode_folder, episode_idx in episode_folders:\n",
        "                \n",
        "        try:\n",
        "            episode_data = process_episode_folder(episode_folder, episode_idx, global_index_offset, last_frames_to_chop)\n",
        "            all_episodes_data.append(episode_data)\n",
        "            \n",
        "            # Update global index offset for the next episode\n",
        "            global_index_offset += episode_data.num_of_frames\n",
        "            #global_index_offset -= last_frames_to_chop\n",
        "            \n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing episode {episode_idx}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Create final output files after processing all episodes\n",
        "    if all_episodes_data:\n",
        "        # Only create tasks parquet for the first episode\n",
        "        create_tasks_parquet(OUTPUT_FOLDER, 'pick_and_place')\n",
        "        \n",
        "        # Create episodes parquet index for all episodes\n",
        "        for _, episode_idx in episode_folders:\n",
        "            create_episodes_parquet_index(OUTPUT_FOLDER, episode_idx)\n",
        "        \n",
        "        update_total_frames_from_episodes(OUTPUT_FOLDER)\n",
        "        \n",
        "        compute_and_save_dataset_stats(OUTPUT_FOLDER)\n",
        "        \n",
        "    else:\n",
        "        print(\"No episodes were successfully processed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/ISDept/piper_arm/tree/main/.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "\n",
        "!hf upload \\\n",
        "  'ISDept/piper_arm' \\\n",
        "  /Users/eddyma/DEV/Github/lerobot-piper/src/output \\\n",
        "  --repo-type dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Webcam inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "!python webcam_inference.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video Inference - Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video inference - SmolVLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python extract_joint_positions.py\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_joint_positions(json_file_path, title, start_frame_index=0):\n",
        "    \"\"\"\n",
        "    Plots joint positions from a JSON file, starting from a specified frame index.\n",
        "    Handles both inference results format and joint positions format.\n",
        "\n",
        "    Parameters:\n",
        "    json_file_path (str): Path to the JSON file.\n",
        "    title (str): Title for the plot.\n",
        "    start_frame_index (int): The frame index from which to start plotting. Defaults to 0 (the beginning).\n",
        "    \"\"\"\n",
        "    # Read the JSON file\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Check if this is inference results format (list of objects with 'result' key)\n",
        "    # or joint positions format (list of arrays)\n",
        "    if isinstance(data, list) and len(data) > 0:\n",
        "        # This is joint positions format (list of arrays)\n",
        "        # For this format, we'll just plot all data starting from start_frame_index\n",
        "        if start_frame_index >= len(data):\n",
        "            print(f\"No data found starting from frame index {start_frame_index}.\")\n",
        "            return\n",
        "        \n",
        "        # Extract joint positions from start_frame_index onward\n",
        "        filtered_data = data[start_frame_index:]\n",
        "        frame_indices = list(range(start_frame_index, start_frame_index + len(filtered_data)))\n",
        "        print(f\"Frames plotted: {len(frame_indices)} (from index {min(frame_indices)} to {max(frame_indices)})\")\n",
        "        \n",
        "        # Initialize lists for each joint\n",
        "        joints = [[] for _ in range(7)]  # 6 joints + 1 gripper\n",
        "        \n",
        "        # Extract joint positions for each frame in the filtered data\n",
        "        for action in filtered_data:\n",
        "            for i in range(7):  # 6 joints + 1 gripper\n",
        "                joints[i].append(action[i])\n",
        "\n",
        "    \n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 4)) # Slightly larger figure for clarity\n",
        "    \n",
        "    # Joint names\n",
        "    joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']\n",
        "    \n",
        "    # Plot each joint with a different color\n",
        "    for i in range(7):\n",
        "        plt.plot(frame_indices, joints[i], label=joint_names[i], marker='o', markersize=3, linewidth=1.5)\n",
        "    \n",
        "    # Add labels and title\n",
        "    plt.xlabel('Frame Index')\n",
        "    plt.ylabel('Joint Position')\n",
        "    plt.title(f\"{title} (Starting from frame {start_frame_index})\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') # Legend outside plot\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions Training')\n",
        "plot_joint_positions('temp/data_20251128_095915_gt.json', 'Ground Truth Joint Positions')\n",
        "plot_joint_positions('temp/inference_actions_close_loop.json', 'Predicted Joint Positions Closed Loop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
        "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
        "# Comment out the old pretrained model path\n",
        " # pretrained_policy_path = \"lerobot/diffusion_pusht\"\n",
        "# Use your newly trained model path instead\n",
        "pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
        "policy = DiffusionPolicy.from_pretrained(\"ISdept/piper_arm\")\n",
        "\n",
        "print(policy.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated plotting functionality using the new plotting utility\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve()))\n",
        "\n",
        "from plotting_utils import plot_joint_positions\n",
        "\n",
        "# Plot the data using the improved function that handles both file formats\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions - Episode 1')\n",
        "plot_joint_positions('temp/metadata_20251113_080958_gt.json', 'Ground Truth Joint Positions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python inspect_local_parquet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-train \\\n",
        "  --dataset.repo_id=ISdept/piper_arm \\\n",
        "  --policy.type=diffusion \\\n",
        "  --output_dir=outputs/train/output_diff3 \\\n",
        "  --job_name=pick_and_place \\\n",
        "  --policy.device=cuda \\\n",
        "  --policy.repo_id=ISdept/piper_arm \\\n",
        "  --wandb.enable=false \\\n",
        "  --dataset.revision=\"main\" \\\n",
        "  --dataset.image_transforms.enable=True \\\n",
        "  --policy.use_separate_rgb_encoder_per_camera=True \\\n",
        "  --policy.crop_shape=[400,400] \\\n",
        "  --save_checkpoint=True \\\n",
        "  --save_freq=2000 \\\n",
        "  \\\n",
        "  --steps=25000 \\\n",
        "  --policy.n_obs_steps=10 \\\n",
        "  --policy.horizon=24 \\\n",
        "  --batch_size=3 \\\n",
        "  --num_workers=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-eval \\\n",
        "  --policy.repo_id=\"ISdept/piper_arm\" \\\n",
        "  --policy.type=\"diffusion\" \\\n",
        "  --policy.device=\"mps\" \\\n",
        "  --env.type=\"aloha\" \\\n",
        "  --eval.n_episodes=10 \\\n",
        "  --output_dir=\"outputs/inference/piper_arm_eval\" \\\n",
        "  --job_name=\"piper_arm_diffusion_eval\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-dataset-viz \\\n",
        "    --repo-id ISdept/piper_arm \\\n",
        "    --episode-index 001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0199, -0.3549, -2.1588])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "(torch.rand(1).item() - 0.5) * 0.01\n",
        "\n",
        "base = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "torch.randn_like(base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frame_time = 0.1\n",
        "[i * frame_time for i in range(24)]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "for_lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
