{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch lerobot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lerobot.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers num2words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training process...\n",
            "Note: We'll use a public dataset for training as our sample is too small\n",
            "Training output will be saved to: model_output\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 168 files: 100%|██████████| 168/168 [00:00<00:00, 3044.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_features: {'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(7,)), 'observation.images.front': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 400, 640)), 'observation.images.gripper': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 400, 640)), 'observation.images.right': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 400, 640))}\n",
            "output_features: {'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(7,))}\n"
          ]
        },
        {
          "ename": "DecodingError",
          "evalue": "The fields `rtc_config` are not valid for SmolVLAConfig",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDecodingError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m train_output_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining output will be saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_output_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mISdept/piper_arm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mISdept/smolvla-piper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/DEV/Github/lerobot-piper/src/train_smolvla.py:87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(output_dir, dataset_id, model_id, push_to_hub, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_features:\u001b[39m\u001b[38;5;124m'\u001b[39m, input_features)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_features:\u001b[39m\u001b[38;5;124m'\u001b[39m, output_features)\n\u001b[0;32m---> 87\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[43mSmolVLAPolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m cfg \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m     90\u001b[0m cfg\u001b[38;5;241m.\u001b[39mn_obs_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/policies/pretrained.py:95\u001b[0m, in \u001b[0;36mPreTrainedPolicy.from_pretrained\u001b[0;34m(cls, pretrained_name_or_path, config, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, strict, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mThe policy is set in evaluation mode by default using `policy.eval()` (dropout modules are\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mdeactivated). To train it, you should first set it back in training mode with `policy.train()`.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mPreTrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pretrained_name_or_path)\n\u001b[1;32m    107\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/lerobot/configs/policies.py:199\u001b[0m, in \u001b[0;36mPreTrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **policy_kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# HACK: Parse the original config to get the config subclass, so that we can\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# apply cli overrides.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This is very ugly, ideally we'd like to be able to do that natively with draccus\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# something like --policy.path (in addition to --policy.type)\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m draccus\u001b[38;5;241m.\u001b[39mconfig_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 199\u001b[0m     orig_config \u001b[38;5;241m=\u001b[39m \u001b[43mdraccus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/argparsing.py:211\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(config_class, config_path, args, prog, exit_on_error, preferred_help)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03mParses the command line arguments and returns an instance of the config class.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    preferred_help: Preferred location to parse help text for fields (< \"inline\" | \"above\" | \"below\" >)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m parser \u001b[38;5;241m=\u001b[39m ArgumentParser(\n\u001b[1;32m    205\u001b[0m     config_class\u001b[38;5;241m=\u001b[39mconfig_class,\n\u001b[1;32m    206\u001b[0m     config_path\u001b[38;5;241m=\u001b[39mconfig_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     preferred_help\u001b[38;5;241m=\u001b[39mpreferred_help,\n\u001b[1;32m    210\u001b[0m )\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/argparsing.py:102\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 102\u001b[0m     args, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_parse_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/argparsing.py:136\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace, is_parse_args)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DraccusException(msg)\n\u001b[0;32m--> 136\u001b[0m parsed_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_postprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_t, unparsed_args\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/argparsing.py:180\u001b[0m, in \u001b[0;36mArgumentParser._postprocessing\u001b[0;34m(self, parsed_args)\u001b[0m\n\u001b[1;32m    178\u001b[0m deflat_d \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdeflatten(parsed_arg_values, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m deflat_d \u001b[38;5;241m=\u001b[39m mergedeep\u001b[38;5;241m.\u001b[39mmerge(file_args, deflat_d)\n\u001b[0;32m--> 180\u001b[0m cfg \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeflat_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/parsers/registry_utils.py:78\u001b[0m, in \u001b[0;36mwithregistry.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Unlike singledispatch we do not directly override the base call\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/parsers/decoding.py:48\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(cls, raw_value)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@withregistry\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[T], raw_value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m canonicalize_union(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_decoding_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/parsers/decoding.py:201\u001b[0m, in \u001b[0;36mdecode_choice_class\u001b[0;34m(cls, raw_value, path)\u001b[0m\n\u001b[1;32m    198\u001b[0m     raw_value\u001b[38;5;241m.\u001b[39mpop(CHOICE_TYPE_KEY)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# return decode(subcls, raw_value)\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_dataclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/for_lerobot/lib/python3.10/site-packages/draccus/parsers/decoding.py:149\u001b[0m, in \u001b[0;36mdecode_dataclass\u001b[0;34m(cls, d, path)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args:\n\u001b[1;32m    148\u001b[0m     formatted_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m extra_args\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DecodingError(path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe fields \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not valid for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstringify_type(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m missing_fields \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    151\u001b[0m     field\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields(origin)\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39minit \u001b[38;5;129;01mand\u001b[39;00m field\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m init_args \u001b[38;5;129;01mand\u001b[39;00m field\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m MISSING \u001b[38;5;129;01mand\u001b[39;00m field\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m MISSING\n\u001b[1;32m    154\u001b[0m ]\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_fields:\n",
            "\u001b[0;31mDecodingError\u001b[0m: The fields `rtc_config` are not valid for SmolVLAConfig"
          ]
        }
      ],
      "source": [
        "# Add parent directory to path to import train module\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "from train_smolvla import train\n",
        "\n",
        "print(\"\\nStarting training process...\")\n",
        "print(\"Note: We'll use a public dataset for training as our sample is too small\")\n",
        "\n",
        "# Create a temporary directory for training output\n",
        "train_output_dir = Path('model_output')\n",
        "\n",
        "print(f\"Training output will be saved to: {train_output_dir}\")\n",
        "\n",
        "#train(output_dir=str(train_output_dir), dataset_id=\"ISdept/piper_arm\")\n",
        "train(output_dir=str(train_output_dir), dataset_id=\"ISdept/piper_arm\", model_id=\"ISdept/smolvla-piper\", resume_from_checkpoint=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# Add the src directory to the path so we can import prepare_dataset\n",
        "from data_processing.prepare_dataset import process_session, create_tasks_parquet, create_episodes_parquet_index, update_total_frames_from_episodes, compute_and_save_dataset_stats, compute_global_stats_for_episodes\n",
        "from data_processing.episode_data import EpisodeData, CameraData\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "ROOT_FOLDER = Path(\"data/piper_training_data/\")  # Root folder containing episode subfolders\n",
        "OUTPUT_FOLDER = Path(\"output/\")  # Output folder for processed dataset\n",
        "REPO_ID = \"ISDept/piper_arm\"  # Your desired Hugging Face repo ID\n",
        "# ---------------------\n",
        "\n",
        "def find_episode_folders(root_folder):\n",
        "    \"\"\"Find all episode folders with naming convention episode1, episode2, etc.\"\"\"\n",
        "    episode_folders = []\n",
        "    pattern = re.compile(r'^episode(\\d+)$', re.IGNORECASE)\n",
        "    \n",
        "    for item in root_folder.iterdir():\n",
        "        if item.is_dir():\n",
        "            match = pattern.match(item.name)\n",
        "            if match:\n",
        "                episode_folders.append((item, int(match.group(1))))\n",
        "    \n",
        "    # Sort by episode number\n",
        "    episode_folders.sort(key=lambda x: x[1])\n",
        "    return episode_folders\n",
        "\n",
        "def find_json_and_videos(episode_folder):\n",
        "    \"\"\"Find JSON file and video files in the episode folder.\"\"\"\n",
        "    json_files = list(episode_folder.glob(\"*.json\"))\n",
        "    if not json_files:\n",
        "        raise FileNotFoundError(f\"No JSON file found in {episode_folder}\")\n",
        "    if len(json_files) > 1:\n",
        "        print(f\"Warning: Multiple JSON files found in {episode_folder}, using {json_files[0]}\")\n",
        "    \n",
        "    json_path = json_files[0]\n",
        "    \n",
        "    # Find video files (assuming common video extensions)\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
        "    video_files = []\n",
        "    for ext in video_extensions:\n",
        "        video_files.extend(episode_folder.glob(f\"*{ext}\"))\n",
        "    \n",
        "    return json_path, video_files\n",
        "\n",
        "def get_camera_name_from_video_path(video_path):\n",
        "    \"\"\"Determine camera name based on video filename content.\"\"\"\n",
        "    filename = video_path.stem.lower()\n",
        "    if 'front' in filename:\n",
        "        return 'front'\n",
        "    elif 'right' in filename:\n",
        "        return 'right'\n",
        "    elif 'gripper' in filename:\n",
        "        return 'gripper'\n",
        "    else:\n",
        "        # Fallback: use the last part of filename after underscore\n",
        "        return video_path.stem.split('_')[-1]\n",
        "      \n",
        "def process_episode_folder(episode_folder, episode_idx, global_index_offset, last_frames_to_chop):\n",
        "    \"\"\"Process a single episode folder.\"\"\"\n",
        "    json_path, video_files = find_json_and_videos(episode_folder)\n",
        "    \n",
        "    # Create CameraData objects from video files\n",
        "    cameras_list = []\n",
        "    for video_path in video_files:\n",
        "        # Extract camera name from filename (you might want to customize this logic)\n",
        "        camera_name = get_camera_name_from_video_path(video_path)\n",
        "        cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "    \n",
        "    episode_data = EpisodeData(\n",
        "        joint_data_json_path=str(json_path), \n",
        "        episode_index=episode_idx, \n",
        "        fps=10, \n",
        "        global_index_offset=global_index_offset, \n",
        "        cameras=cameras_list,\n",
        "        folder = episode_folder,\n",
        "        task_description = \"Pick up the cube and place it into the container.\"\n",
        "    )\n",
        "    \n",
        "    # Process the first episode differently to create initial files\n",
        "    is_first_episode = (episode_idx == 1)\n",
        "    num_of_frames = process_session(episode_data, OUTPUT_FOLDER, is_first_episode, last_frames_to_chop)\n",
        "    episode_data.num_of_frames = num_of_frames\n",
        "    return episode_data\n",
        "\n",
        "def main():\n",
        "    # Find all episode folders\n",
        "    episode_folders = find_episode_folders(ROOT_FOLDER)\n",
        "    \n",
        "    if not episode_folders:\n",
        "        print(f\"No episode folders found in {ROOT_FOLDER}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Found {len(episode_folders)} episode folders\")\n",
        "    \n",
        "    # First, collect all episode data without processing to compute global statistics\n",
        "    print(\"Collecting episode data for global statistics computation...\")\n",
        "    all_episodes_data = []\n",
        "    \n",
        "    # Store episode-specific parameters\n",
        "    episode_params = {}\n",
        "    \n",
        "    last_frames_to_chop = 30  # Default value\n",
        "    for episode_folder, episode_idx in episode_folders:    \n",
        "        if episode_idx == 3:\n",
        "            last_frames_to_chop = 42\n",
        "        elif episode_idx == 7 or episode_idx == 32 or episode_idx == 46 or episode_idx == 76 or episode_idx == 87 or episode_idx == 88 \\\n",
        "          or episode_idx ==  89 or episode_idx == 102 or episode_idx == 103 or episode_idx == 108 or episode_idx == 110 or episode_idx == 118 \\\n",
        "          or episode_idx == 119 or episode_idx == 120 or episode_idx == 121 or episode_idx == 122 or episode_idx == 126 or episode_idx == 152:\n",
        "            last_frames_to_chop = 38\n",
        "        elif episode_idx == 11 or episode_idx == 14 or episode_idx == 17 or episode_idx == 25 or episode_idx == 37 or episode_idx == 132:\n",
        "            last_frames_to_chop = 32\n",
        "        elif episode_idx == 15 or episode_idx == 30 or episode_idx == 38 or episode_idx == 40 or episode_idx == 41 or episode_idx == 42 \\\n",
        "          or episode_idx == 49 or episode_idx == 51 or episode_idx == 52 or episode_idx == 56 or episode_idx == 57 or episode_idx == 65 \\\n",
        "          or episode_idx == 68 or episode_idx == 70 or episode_idx == 74 or episode_idx == 78 or episode_idx == 79 or episode_idx == 81 \\\n",
        "          or episode_idx == 82 or episode_idx == 83 or episode_idx == 84 or episode_idx == 91 or episode_idx == 104 or episode_idx == 105 \\\n",
        "          or episode_idx == 106 or episode_idx == 127 or episode_idx == 144 or episode_idx == 146 or episode_idx == 147 or episode_idx == 148 \\\n",
        "            or episode_idx == 149:\n",
        "            last_frames_to_chop = 30\n",
        "        elif episode_idx == 137:\n",
        "            last_frames_to_chop = 24\n",
        "        elif episode_idx == 44 or episode_idx == 162 or episode_idx == 164:\n",
        "            last_frames_to_chop = 25\n",
        "        elif episode_idx == 129:\n",
        "            last_frames_to_chop = 18\n",
        "        elif episode_idx > 129 :\n",
        "            last_frames_to_chop = 28\n",
        "        elif episode_idx < 129:\n",
        "            last_frames_to_chop = 35\n",
        "        \n",
        "        # Store parameters for this episode\n",
        "        episode_params[episode_idx] = {\n",
        "            'last_frames_to_chop': last_frames_to_chop\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            # Create episode data object (without processing yet)\n",
        "            json_path, video_files = find_json_and_videos(episode_folder)\n",
        "            \n",
        "            # Create CameraData objects from video files\n",
        "            cameras_list = []\n",
        "            for video_path in video_files:\n",
        "                # Extract camera name from filename (you might want to customize this logic)\n",
        "                camera_name = get_camera_name_from_video_path(video_path)\n",
        "                cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "            \n",
        "            episode_data = EpisodeData(\n",
        "                joint_data_json_path=str(json_path), \n",
        "                episode_index=episode_idx, \n",
        "                fps=10, \n",
        "                global_index_offset=0,  # Will be updated during processing\n",
        "                cameras=cameras_list,\n",
        "                folder = episode_folder,\n",
        "                task_description = \"Pick up the cube and place it into the container.\",\n",
        "                last_frames_to_chop = last_frames_to_chop\n",
        "            )\n",
        "            \n",
        "            all_episodes_data.append(episode_data)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error collecting data from episode {episode_idx}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Compute global statistics\n",
        "    if all_episodes_data:\n",
        "        print(\"Computing global statistics...\")\n",
        "        global_means, global_stds = compute_global_stats_for_episodes(all_episodes_data, ROOT_FOLDER)\n",
        "        print(f\"Global means: {global_means}\")\n",
        "        print(f\"Global stds: {global_stds}\")\n",
        "    else:\n",
        "        print(\"No episodes found for global statistics computation\")\n",
        "        return\n",
        "    \n",
        "    # Now process all episodes in a single pass with global statistics\n",
        "    print(\"Processing episodes with global statistics...\")\n",
        "    processed_episodes_data = []\n",
        "    global_index_offset = 0\n",
        "    \n",
        "    for episode in all_episodes_data:\n",
        "                \n",
        "        episode_folder = episode.folder\n",
        "        episode_idx = episode.episode_index\n",
        "        last_frames_to_chop = episode.last_frames_to_chop\n",
        "        \n",
        "        print(f\"Processing episode {episode_idx} in folder {episode_folder}\")\n",
        "        \n",
        "        try:\n",
        "            # Create episode data with correct global index offset\n",
        "            json_path, video_files = find_json_and_videos(episode_folder)\n",
        "            \n",
        "            # Create CameraData objects from video files\n",
        "            cameras_list = []\n",
        "            for video_path in video_files:\n",
        "                # Extract camera name from filename (you might want to customize this logic)\n",
        "                camera_name = get_camera_name_from_video_path(video_path)\n",
        "                cameras_list.append(CameraData(video_path=str(video_path), camera=camera_name))\n",
        "            \n",
        "                        \n",
        "            # Process the first episode differently to create initial files\n",
        "            is_first_episode = (episode_idx == 1)\n",
        "            num_of_frames = process_session(episode, OUTPUT_FOLDER, is_first_episode, last_frames_to_chop, global_means=global_means, global_stds=global_stds)\n",
        "            episode.num_of_frames = num_of_frames\n",
        "            \n",
        "            # Update global index offset for the next episode\n",
        "            global_index_offset += episode.num_of_frames\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing episode {episode_idx}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Create final output files after processing all episodes\n",
        "    if all_episodes_data:\n",
        "        # Only create tasks parquet for the first episode\n",
        "        create_tasks_parquet(OUTPUT_FOLDER, 'pick_and_place')\n",
        "        \n",
        "        # Create episodes parquet index for all episodes\n",
        "        for _, episode_idx in episode_folders:\n",
        "            create_episodes_parquet_index(OUTPUT_FOLDER, episode_idx)\n",
        "        \n",
        "        update_total_frames_from_episodes(OUTPUT_FOLDER)\n",
        "        \n",
        "        # Compute and save dataset statistics\n",
        "        compute_and_save_dataset_stats(OUTPUT_FOLDER)\n",
        "        \n",
        "        print(\"Dataset preparation completed successfully with global standardization!\")\n",
        "    else:\n",
        "        print(\"No episodes were successfully processed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "\n",
        "!hf upload \\\n",
        "  'ISDept/piper_arm' \\\n",
        "  /Users/eddyma/DEV/Github/lerobot-piper/src/output \\\n",
        "  --repo-type dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Webcam inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "!python webcam_inference.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video Inference - Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video inference - SmolVLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python video_inference_smolvla_close_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python extract_joint_positions.py\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_joint_positions(json_file_path, title, start_frame_index=0):\n",
        "    \"\"\"\n",
        "    Plots joint positions from a JSON file, starting from a specified frame index.\n",
        "    Handles both inference results format and joint positions format.\n",
        "\n",
        "    Parameters:\n",
        "    json_file_path (str): Path to the JSON file.\n",
        "    title (str): Title for the plot.\n",
        "    start_frame_index (int): The frame index from which to start plotting. Defaults to 0 (the beginning).\n",
        "    \"\"\"\n",
        "    # Read the JSON file\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Check if this is inference results format (list of objects with 'result' key)\n",
        "    # or joint positions format (list of arrays)\n",
        "    if isinstance(data, list) and len(data) > 0:\n",
        "        # This is joint positions format (list of arrays)\n",
        "        # For this format, we'll just plot all data starting from start_frame_index\n",
        "        if start_frame_index >= len(data):\n",
        "            print(f\"No data found starting from frame index {start_frame_index}.\")\n",
        "            return\n",
        "        \n",
        "        # Extract joint positions from start_frame_index onward\n",
        "        filtered_data = data[start_frame_index:]\n",
        "        frame_indices = list(range(start_frame_index, start_frame_index + len(filtered_data)))\n",
        "        print(f\"Frames plotted: {len(frame_indices)} (from index {min(frame_indices)} to {max(frame_indices)})\")\n",
        "        \n",
        "        # Initialize lists for each joint\n",
        "        joints = [[] for _ in range(7)]  # 6 joints + 1 gripper\n",
        "        \n",
        "        # Extract joint positions for each frame in the filtered data\n",
        "        for action in filtered_data:\n",
        "            for i in range(7):  # 6 joints + 1 gripper\n",
        "                joints[i].append(action[i])\n",
        "\n",
        "    \n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 4)) # Slightly larger figure for clarity\n",
        "    \n",
        "    # Joint names\n",
        "    joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']\n",
        "    \n",
        "    # Plot each joint with a different color\n",
        "    for i in range(7):\n",
        "        plt.plot(frame_indices, joints[i], label=joint_names[i], marker='o', markersize=3, linewidth=1.5)\n",
        "    \n",
        "    # Add labels and title\n",
        "    plt.xlabel('Frame Index')\n",
        "    plt.ylabel('Joint Position')\n",
        "    plt.title(f\"{title} (Starting from frame {start_frame_index})\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') # Legend outside plot\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions Training')\n",
        "plot_joint_positions('temp/data_20251128_095915_gt.json', 'Ground Truth Joint Positions')\n",
        "plot_joint_positions('temp/inference_actions_close_loop.json', 'Predicted Joint Positions Closed Loop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
        "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
        "# Comment out the old pretrained model path\n",
        " # pretrained_policy_path = \"lerobot/diffusion_pusht\"\n",
        "# Use your newly trained model path instead\n",
        "pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
        "policy = DiffusionPolicy.from_pretrained(\"ISdept/piper_arm\")\n",
        "\n",
        "print(policy.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated plotting functionality using the new plotting utility\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve()))\n",
        "\n",
        "from plotting_utils import plot_joint_positions\n",
        "\n",
        "# Plot the data using the improved function that handles both file formats\n",
        "plot_joint_positions('temp/inference_actions.json', 'Predicted Joint Positions - Episode 1')\n",
        "plot_joint_positions('temp/metadata_20251113_080958_gt.json', 'Ground Truth Joint Positions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python inspect_local_parquet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-train \\\n",
        "  --dataset.repo_id=ISdept/piper_arm \\\n",
        "  --policy.type=diffusion \\\n",
        "  --output_dir=outputs/train/output_diff3 \\\n",
        "  --job_name=pick_and_place \\\n",
        "  --policy.device=cuda \\\n",
        "  --policy.repo_id=ISdept/piper_arm \\\n",
        "  --wandb.enable=false \\\n",
        "  --dataset.revision=\"main\" \\\n",
        "  --dataset.image_transforms.enable=True \\\n",
        "  --policy.use_separate_rgb_encoder_per_camera=True \\\n",
        "  --policy.crop_shape=[400,400] \\\n",
        "  --save_checkpoint=True \\\n",
        "  --save_freq=2000 \\\n",
        "  \\\n",
        "  --steps=25000 \\\n",
        "  --policy.n_obs_steps=10 \\\n",
        "  --policy.horizon=24 \\\n",
        "  --batch_size=3 \\\n",
        "  --num_workers=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-eval \\\n",
        "  --policy.repo_id=\"ISdept/piper_arm\" \\\n",
        "  --policy.type=\"diffusion\" \\\n",
        "  --policy.device=\"mps\" \\\n",
        "  --env.type=\"aloha\" \\\n",
        "  --eval.n_episodes=10 \\\n",
        "  --output_dir=\"outputs/inference/piper_arm_eval\" \\\n",
        "  --job_name=\"piper_arm_diffusion_eval\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lerobot-dataset-viz \\\n",
        "    --repo-id ISdept/piper_arm \\\n",
        "    --episode-index 002 \\\n",
        "    --root /Users/eddyma/DEV/Github/lerobot-piper/src/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.1, 0.0]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obs_temporal_window = [ -i * 0.1 for i in range(2) ][::-1]\n",
        "obs_temporal_window"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "for_lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
