{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAM2 Segmentation with Webcam Demo\n",
        "\n",
        "This notebook demonstrates how to use SAM2 segmentation with frames captured from a webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if not already installed\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Check if segment-anything is installed\n",
        "try:\n",
        "    import segment_anything\n",
        "except ImportError:\n",
        "    print(\"Installing segment-anything...\")\n",
        "    install_package(\"git+https://github.com/facebookresearch/segment-anything.git\")\n",
        "\n",
        "print(\"Required packages are installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add src to path to import our custom SAM2 segmentation class\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().resolve()))\n",
        "\n",
        "from sam2_segmentation import SAM2Segmentation\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize SAM2 segmentation\n",
        "\n",
        "sam_seg = SAM2Segmentation(\"src/sam2.1_b.pt\", \"vit_b\")  # Using base model for speed\n",
        "\n",
        "# Load model\n",
        "if not sam_seg.load_model():\n",
        "    print(\"Failed to load SAM2 model\")\n",
        "else:\n",
        "    print(\"SAM2 model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to capture a single frame from webcam\n",
        "\n",
        "def capture_frame(webcam_id=0):\n",
        "    \"\"\"\n",
        "    Capture a single frame from the webcam.\n",
        "    \n",
        "    Args:\n",
        "        webcam_id (int): ID of the webcam to use (default: 0)\n",
        "        \n",
        "    Returns:\n",
        "        np.ndarray: Captured frame, or None if failed\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(webcam_id)\n",
        "    \n",
        "    if not cap.isOpened():\n",
        "        print(f\"Cannot open webcam {webcam_id}\")\n",
        "        return None\n",
        "    \n",
        "    # Set resolution (optional)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "    \n",
        "    # Capture frame\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    \n",
        "    if not ret:\n",
        "        print(\"Failed to capture frame\")\n",
        "        return None\n",
        "    \n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Capture a frame and perform segmentation\n",
        "\n",
        "print(\"Capturing frame from webcam...\")\n",
        "frame = capture_frame()\n",
        "\n",
        "if frame is not None:\n",
        "    print(\"Frame captured successfully. Performing segmentation...\")\n",
        "    \n",
        "    # Perform segmentation\n",
        "    start_time = time.time()\n",
        "    result = sam_seg.segment_frame(frame)\n",
        "    inference_time = time.time() - start_time\n",
        "    \n",
        "    if result is not None:\n",
        "        print(f\"Segmentation completed in {inference_time:.2f} seconds\")\n",
        "        \n",
        "        # Visualize results\n",
        "        vis_frame = sam_seg.visualize_segmentation(frame, result)\n",
        "        \n",
        "        # Convert BGR to RGB for matplotlib\n",
        "        vis_frame_rgb = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
        "        original_frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Display results\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
        "        \n",
        "        axes[0].imshow(original_frame_rgb)\n",
        "        axes[0].set_title(\"Original Frame\")\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        axes[1].imshow(vis_frame_rgb)\n",
        "        axes[1].set_title(f\"SAM2 Segmentation Results (Time: {inference_time:.2f}s)\")\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print segmentation info\n",
        "        masks = result.get(\"masks\", None)\n",
        "        scores = result.get(\"scores\", np.array([]))\n",
        "        \n",
        "        if masks is not None and len(masks) > 0:\n",
        "            print(f\"\\nGenerated {len(masks)} segmentation masks:\")\n",
        "            for i, (mask, score) in enumerate(zip(masks, scores)):\n",
        "                mask_area = np.sum(mask > 0.5) if mask.dtype != np.uint8 else np.sum(mask)\n",
        "                print(f\"  - Mask {i+1}: Score {score:.3f}, Area {mask_area} pixels\")\n",
        "        else:\n",
        "            print(\"No segmentation masks generated.\")\n",
        "    else:\n",
        "        print(\"Segmentation failed.\")\n",
        "else:\n",
        "    print(\"Failed to capture frame from webcam.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-time Webcam Segmentation\n",
        "\n",
        "The following cell will start a real-time segmentation demo. Press the stop button (⏹️) in Jupyter to stop the demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Real-time webcam segmentation demo\n",
        "# Note: This will run continuously until stopped manually\n",
        "\n",
        "print(\"Starting real-time webcam segmentation demo...\")\n",
        "print(\"Press the stop button (⏹️) in Jupyter to stop the demo.\")\n",
        "\n",
        "# Open webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Cannot open webcam\")\n",
        "else:\n",
        "    try:\n",
        "        while True:\n",
        "            # Capture frame\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Failed to capture frame\")\n",
        "                break\n",
        "            \n",
        "            # Perform segmentation\n",
        "            start_time = time.time()\n",
        "            result = sam_seg.segment_frame(frame)\n",
        "            inference_time = time.time() - start_time\n",
        "            \n",
        "            if result is not None:\n",
        "                # Visualize results\n",
        "                vis_frame = sam_seg.visualize_segmentation(frame, result)\n",
        "                \n",
        "                # Add FPS counter\n",
        "                fps = 1.0 / inference_time if inference_time > 0 else 0\n",
        "                cv2.putText(vis_frame, f\"SAM2 FPS: {fps:.1f}\", (10, 30),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "                \n",
        "                # Convert to RGB for matplotlib\n",
        "                vis_frame_rgb = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
        "                \n",
        "                # Display frame\n",
        "                clear_output(wait=True)\n",
        "                plt.figure(figsize=(12, 8))\n",
        "                plt.imshow(vis_frame_rgb)\n",
        "                plt.title(\"Real-time SAM2 Segmentation\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "                \n",
        "                # Print segmentation info\n",
        "                masks = result.get(\"masks\", None)\n",
        "                if masks is not None:\n",
        "                    print(f\"Generated {len(masks)} masks (FPS: {fps:.1f})\")\n",
        "                else:\n",
        "                    print(f\"No masks generated (FPS: {fps:.1f})\")\n",
        "            else:\n",
        "                print(\"Segmentation failed\")\n",
        "                \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Demo interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during demo: {e}\")\n",
        "    finally:\n",
        "        # Clean up\n",
        "        cap.release()\n",
        "        plt.close('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Point-based Segmentation\n",
        "\n",
        "SAM2 excels at point-based segmentation. Here's how you can interactively select points for segmentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive point-based segmentation example\n",
        "# This would require additional UI components in a full implementation\n",
        "\n",
        "print(\"Interactive point-based segmentation:\")\n",
        "print(\"In a full implementation, you would be able to click on the image to select points for segmentation.\")\n",
        "print(\"Points can be labeled as foreground (positive) or background (negative) to guide the segmentation.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}